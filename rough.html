
                    <div class="break">
                        <span class="break-type">Coffee Break</span>
                        <span>10:30 - 11:00</span>
                    </div>
                    
                    <div class="session">
                        <div class="session-header">
                            <h4>Session 1: Eye-Tracking for Language Model Evaluation</h4>
                            <span class="session-time">11:00 - 12:30</span>
                        </div>
                        <div class="session-content">
                            <div class="paper">
                                <div class="paper-title">Predicting Human Reading Patterns with Transformer-based Language Models</div>
                                <div class="paper-authors">John Smith, Sarah Johnson, University of Technology</div>
                                <p>This paper presents a novel approach to predicting human reading patterns using transformer architectures, demonstrating significant improvements over previous methods.</p>
                            </div>
                            
                            <div class="paper">
                                <div class="paper-title">Eye-Tracking as a Tool for Evaluating LLM Comprehension Abilities</div>
                                <div class="paper-authors">Maria Garcia, David Chen, Research Institute of AI</div>
                                <p>We introduce a new framework for evaluating large language models by comparing their attention mechanisms with human eye-tracking data during reading tasks.</p>
                            </div>
                            
                            <div class="paper">
                                <div class="paper-title">Cross-lingual Eye Movement Patterns in Multilingual Readers</div>
                                <div class="paper-authors">Robert Lee, Anna MÃ¼ller, International University</div>
                                <p>This study examines how multilingual readers' eye movement patterns differ when reading in their first versus second languages, with implications for cross-lingual NLP models.</p>
                            </div>
                        </div>
                    </div>
                    
                    <div class="break">
                        <span class="break-type">Lunch Break</span>
                        <span>12:30 - 14:00</span>
                    </div>
                    
                    <div class="session">
                        <div class="session-header">
                            <h4>Session 2: Gaze Data Collection and Processing</h4>
                            <span class="session-time">14:00 - 15:30</span>
                        </div>
                        <div class="session-content">
                            <div class="paper">
                                <div class="paper-title">GazeBERT: A Neural Architecture for Integrating Eye-Tracking Signals with Linguistic Features</div>
                                <div class="paper-authors">Jennifer Wilson, Michael Brown, Tech University</div>
                                <p>We present GazeBERT, a novel architecture that incorporates eye-tracking signals directly into the BERT framework to enhance language understanding tasks.</p>
                            </div>
                            
                            <div class="paper">
                                <div class="paper-title">Low-Cost Eye-Tracking Solutions for Large-Scale Data Collection</div>
                                <div class="paper-authors">Thomas Anderson, Lisa Zhang, Analytics Institute</div>
                                <p>This paper explores how consumer-grade webcams can be used for reliable eye-tracking data collection, making large-scale studies more accessible to NLP researchers.</p>
                            </div>
                            
                            <div class="paper">
                                <div class="paper-title">Standardized Protocols for Eye-Tracking Data in NLP Research</div>
                                <div class="paper-authors">Kevin Martinez, Emma White, National Research Lab</div>
                                <p>We propose a set of standardized protocols for collecting, preprocessing, and sharing eye-tracking data to facilitate reproducibility and collaboration in NLP research.</p>
                            </div>
                        </div>
                    </div>
                    
                    <div class="break">
                        <span class="break-type">Coffee Break</span>
                        <span>15:30 - 16:00</span>
                    </div>
                    
                    <div class="session">
                        <div class="session-header">
                            <h4>Poster Session 1</h4>
                            <span class="session-time">16:00 - 17:30</span>
                        </div>
                        <div class="session-content">
                            <p>Poster presentations of selected papers. The complete list of posters will be available in the conference program.</p>
                        </div>
                    </div>
                    
                    <div class="special-session">
                        <h4>Evening Reception</h4>
                        <p><strong>Time:</strong> 18:00 - 20:00</p>
                        <p><strong>Location:</strong> University Atrium</p>
                        <p>Join us for the welcome reception with refreshments and networking opportunities.</p>
                    </div>
                </div>
            </div>
            
            <div class="download-buttons">
                <a href="#" class="btn">Download Full Schedule (PDF)</a>
                <a href="#" class="btn btn-outline">Add to Calendar</a>
            </div>
        </div>